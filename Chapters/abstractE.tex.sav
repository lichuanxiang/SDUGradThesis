\begin{englishabstract}
\eabstract{Abstract in English}

Recent years have witnessed the era of information explosion, in which the rapid development of information technology, i.e., Internet, e-commerce, cloud computing and mobile social media, has led to a sharp increase in the number and size of data, and the expression of data has become more diverse, including multiple modalities such as image, video, audio, text, optical flow information, etc. Large-scale multi-modal data put forward higher requirements on data processing and storage capacity, which is not only to process large-scale data in an acceptable time, but also limit the storage capacity of data to an acceptable range. This is still a challenge for the retrieval of large-scale multi-modal data, and it has led to more and more researches and discussions because of its practicability and effectiveness.

Hashing emerges in order to solve the problem of approximate nearest neighbor retrieval for high-dimensional large-scale data. By mapping high-dimensional data into low-dimensional Hamming space while maintaining the similarity between data in the original space as much as possible, the original data can be represented as a fixed-length binary code and maintain the original similarity information such as semantic relations in Hamming space. Since the retrieval can be efficiently implemented by calculating the Hamming distance between binary codes by XOR operation, and the storage complexity of the fixed-length binary code is low, hashing methods have received extensive attention.

Most of the traditional hashing methods are mainly for single-modal data, which solves the problem of data retrieval in a single modality. With the rapid development of information technology and the explosive growth of data, multi-modal data is increasing. Therefore, there are more and more requirements for cross-modal retrieval, such as using text to retrieve image, and cross-modal hashing retrieval becomes an effective solution.

At present, there are many cross-modal hashing methods, and have achieved great retrieval performance, but there are still some limitations on their performance: As the binary discrete optimization problem is more difficult to solve, some methods relax the discrete conditions by first obtaining the real-valued representation of the hash code, and then binarizing the obtained real-valued representation to obtain the final hash code. However, the relaxation optimization will generate a large quantization error, leading to poor retrieval performance. There are also some methods for direct discrete optimization, but the time required for optimization is greatly increased. In the choice of supervised information, some methods choose to use n$\times$n similarity matrix for similarity maintaining, which will increase the time complexity of training from linear $O(n)$ to $O(n^2)$, making it harder to extend to large-scale datasets.

After comprehensively considering the above problems, this paper proposes a new supervised hashing method¡ªScalable disCRete mATrix faCtorization Hashing, SCRATCH for short. It leverages the collective matrix factorization on the kernelized features and the semantic embedding with labels to find a latent semantic space to preserve the intra- and inter-modality similarities. In addition, it incorporates the label matrix instead of the similarity matrix into the loss function, so that its time complexity is linear to the size of the dataset, making it scalable to large-scale datasets. Moreover, in order to avoid the large quantization error caused by using relaxation technique to solve the discrete optimization problem, we introduce the random orthogonal rotation matrix to keep the discrete property of hash codes in the whole training stage, which can minimize the quantization error and avoid the time-consuming optimization process of other discrete optimization methods because of the matrix optimization. Finally, SCRATCH proposes a iterative optimization algorithm to further reduce the quantization error.

By comparing experiments on three multi-modal datasets, including retrieval performance, training time, and using a deep network as image feature extractor with loss function of SCRATCH to compare the retrieval performance with current advanced deep cross-modal hashing methods, we can see that SCRATCH achieves state-of-the-art performance on three benchmark multi-modal datasets and the training time is greatly reduced, which means that it is extremely effective and practical and can be easily extended to large-scale datasets.

\vspace{2em}
\begin{tabular*}{\textwidth}{ll}
%\hspace{-2.5em}
\noindent\textbf{Keywords:} Hash learning; Cross-modal retrieval; Matrix factorization; Discrete\\
optimization; Approximate nearest neighbor search
\end{tabular*}

\end{englishabstract}
