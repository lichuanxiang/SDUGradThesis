\chapter{\quad\quad 总结与展望}
\label{chap6}
\echapter{Conclusions and Future Works}

\section{总结}
\esection{Conclusions}

近年来，随着信息技术的飞速发展以及移动设备和新兴社交网站的流行，多媒体数据呈现爆炸式的增长，海量多模态数据数据量大、特征维度高以及要求响应速度快等特点，哈希方法因其存储小检索快的优点，为在这些浩瀚的多模态数据库中方便、快速、准确地查询并检索到用户所需的或感兴趣的模态信息提供了解决方案，因此逐渐成为大规模多媒体数据信息检索领域研究的热点。

目前已有很多跨模态哈希方法提出，并取得了不错的跨模态检索效果，但是仍有几个限制其性能的问题存在：1) 一些方法对离散条件进行松弛化，导致生成的哈希码有较大的量化误差，使得最终哈希码的检索效果下降；2) 也有一些方法直接进行离散优化，但都以牺牲训练时间为代价，导致优化所需时间大大增加；3) 在监督信息的选择上，有的方法选择使用\ $n\times n$ 的相似性矩阵进行相似性保持，但这会导致其训练的时间复杂度上升到$O(n^2)$，进而增加了其扩展到大规模数据集的难度。

综合考虑上述问题之后，本文提出一种新的有监督哈希方法――基于矩阵分解的可扩展离散哈希，简称为\ SCRATCH。该方法对原始特征核化后进行矩阵分解，并结合标签信息的语义嵌入来产生一个公共子空间，从而尽可能的保持模态间和模态内的语义相似性；同时，通过使用标签矩阵而非相似性矩阵，该方法的训练复杂度始终与数据集规模保持为线性关系，可方便的扩展到大规模多模态数据集上；为了解决离散优化问题，引入正交旋转矩阵来最小化训练过程中的量化误差，并使用迭代优化的方式来进一步减小量化误差。我们在三个常用基准数据集上的实验表明，SCRATCH 可达到当前哈希检索的先进水平，若结合深度特征可进一步提升其跨模态检索性能，同时还具有训练速度快、已扩展到大规模数据集等优点，展现出极高的有效性和实用性。



\section{展望}
\esection{Future Works}

值得一提的是，SCRATCH 本身是一个非深度跨模态检索模型，因为我们设计改模型的初衷在于损失函数和优化策略的创新性。如小节（3.3.6）所示，尽管\ SCRATCH 不是一个端到端的深度模型（不可同时训练网络和\ SCRATCH 模型，特征提取和模型训练是分开的），仍能取得超越当前先进的深度跨模态哈希方法（DCMH）的检索性能，说明\ SCRATCH 采用的损失函数和优化策略是正确且有效的，考虑到端到端的卷积神经网络和哈希学习训练可以使得两者的结合更加紧密，同时也会得到更好地检索效果，因此我们计划将现有的损失函数嵌入到深度神经网络中，将多模态的映射函数也是用深度神经网络来代替，从而建立一个端到端的深度跨模态哈希模型。

除此之外，由于我们的方法使用了显式的语义标签参与训练，同时使用了矩阵分解来挖掘多模态数据隐含的语义信息并去除冗余信息，因此本文\ SCRATCH 模型学到的哈希码比起单独的语义标签来说，同时结合了显式和隐式的丰富语义信息，如果将得到的哈希码用于分类，我们预测最终效果应该好于使用原始特征进行分类，因为原始数据的隐含语义信息未被挖掘，同时还可能包含大量噪声，对最终的分类结果影响很大。使用哈希码进行分类的另一个好处是，相当于对原始数据进行了降维处理，这样不仅减小了数据的存储空间和分类器训练的消耗，与此同时也大大提高了分类器的性能。


%\cleardoublepage
