\chapter{\quad\quad 总结与展望}
\label{chap6}
\echapter{Conclusions and Future Works}

\section{总结}
\esection{Conclusions}

在面对大规模及复杂媒体数据的检索任务时，哈希学习技术不失为一个很好的选择。哈希学习技术可以降低媒体数据的存储消耗，并且可以提高检索任务的效率。此外，很多真实应用表明，监督哈希学习技术相比于无监督哈希技术，有着更优异的效果。因此，本文在基于哈希学习的大规模媒体检索研究方面进行了深入研究。更具体的，我们设计了四种监督哈希模型来进行大规模媒体检索。

本文在基于哈希学习的大规模媒体检索研究方面进行了如下的研究工作。


1.通过分析与观察之后，我们发现属于相同类别的数据的哈希码应相同。在此基础上，我们只需要为每一个类别学习出一个类别哈希码，并使之保持住类别之间的相似性即可。这样，训练的时候便无需考虑具体的样本，从而使得我们的训练时间及空间消耗不再受数据量的限制，因此我们可以在极短的时间内以及极低的内存使用下完成模型的训练，并且可以扩展到大规模媒体数据上。

2.监督哈希学习通用的目标函数涉及到一个数据量平方大小的样本间成对相似性矩阵，这个矩阵的存在使得哈希学习的时间复杂度很高，从而无法进行大规模媒体检索任务。为了解决这个问题，且不采用会导致信息损失的采样技术，我们通过替换目标函数中的一个哈希码项，进而引入了一个大小只与数据量线性相关的中间项。这个中间项是成对的相似性矩阵与标签矩阵的乘积，且是一个可以在优化前预先计算的常数项。通过在优化中直接使用该中间项，我们避免了使用成对相似性矩阵造成的很高的时间复杂度及很大的空间消耗。并且我们使用了离散优化算法去求解哈希码，这样得到的哈希码可以避免引入较大的量化误差。

3.尽管我们已经可以用一个中间项来规避直接使用数据量平方大小的样本间成对相似性矩阵，但是这个中间项是与数据量成线性相关的，当数据量足够大的时候，仍会有很高的消耗。在第三章中，我们提出了另外一种监督哈希方法。类似的，该方法也引入了一个中间项，可以在不采用会导致信息损失的采样技术的情况下，避免在优化过程中直接使用样本间成对的相似性矩阵。这个中间项的大小与数据量无关，只与类别数及特征的维数有关，因此其远小于样本间成对的相似性矩阵。除此之外，哈希码的生成不仅受益于监督信息，还会考虑到数据的特征信息，并且我们采用了一步优化所有位哈希码的离散优化算法。因此，本章提出的方法可以准确并高效地完成哈希码的更新。实验及理论分析均显示了该方法优于现有的监督哈希方法及上一章所提出的方法。

4.除了单个模态内的媒体数据检索，跨模态媒体检索也是值得研究的方向，并且在现实生活中有着广泛的应用。因此我们设计了一种跨模态监督哈希方法。该方法充分考虑了数据的流形结构及语义信息，并且使用离散优化策略以保证哈希码能被准确地学出。我们在公用的数据集上进行了大量的实验，实验的结果表明我们设计的跨模态哈希检索技术是十分有效的。



\section{展望}
\esection{Future Works}

使用哈希学习方法进行大规模媒体检索任务是非常有意义的工作。本文仅仅是对该问题的初步探索，仍有很多有意义的问题值得去研究。

对于本文设计的方法来说，仍有可以提高的地方。比如，对于本文第二章中的方法，我们可以使用离散优化的策略进一步提高哈希码的质量。且可以将该方法扩展到多标签的媒体数据检索任务上。再比如，对于本文的方法，我们均可以进一步结合深度学习技术，利用深度学习方法强大的特征学习能力来提高媒体检索的准确性。

而对于哈希学习来说，其研究才刚刚起步\cite{li2015learning}。哈希学习理论分析的工作还需要更深入的研究。哈希学习把原始数据有损的量化成二进制哈希码，其中到底有多少损失，如何能最大程度接近利用原始数据学到的模型是一个研究方向。此外，在检索的时候，多少位的哈希码可以保证足够的准确度，如何从理论上选择哈希码的位数也值得研究。面对大规模的数据，多机器集群的分布式学习方式显然会更加适用，如何把分布式学习与哈希学习结合起来也不失为一个实际的研究方向。












%\cleardoublepage
