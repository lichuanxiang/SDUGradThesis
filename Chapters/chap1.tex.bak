\chapter{\quad\quad绪\quad论}
\echapter{Introduction}
\label{chap1}

\section{课题研究背景及意义}
\esection{Background and motivation of Research}

\subsection{研究背景}
\esubsection{Background of research}

近年来，随着信息技术的飞速发展以及移动设备和新兴社交网站（如微博、Facebook、Flickr 和\ Twitter等）的流行，图像、视频、音频、文本等多媒体数据在数量和规模上飞速增长。针对这些蕴含巨大信息量的海量多模态数据，多模态信息检索关注的主要问题是如何在保证检索精度的前提下，从大规模的多模态数据库中快速地返回用户所查询的模态信息（如文本或图片等）。由于当前的多模态数据库有数据量大、特征维度高以及要求响应速度快等特点，因此多模态数据检索目前仍是一个难点。

解决多模态数据检索难题最直接的解决方案是精确近邻检索，最典型的方法是K近邻法（K Nearst Neighbors, KNN）\cite{altman1992knn}，计算待检索的请求样本与数据库中所有样本的相似性（通常使用距离度量或余弦相似性），然后找出相似性最大（距离最小或余弦相似性最大）的\ K 个样本作为检索候选样本返回。然而，精确近邻检索的问题在于计算量过大，对于高维大规模数据来说并不实用，无法达到应用效果。

实际应用中，近似近邻检索（Approximate Nearst Neighbors, ANN）\cite{Tang15Neighborhood,hinton03stochastic,wang2015facilitating,liu2016query,nie12Harvesting,Song2013Effective,luo2018fast,Wang2016luh,Yang2017dmvh}在多模态数据检索中起到了关键作用，在检索结果得到保证的同时大幅度降低了查询的响应时间，在实用性和有效性方面得到了很大程度的提升。当前对于近似近邻检索方法的研究主要分为基于树形结构和基于哈希方法两个方向，实践表明基于哈希方法的近似近邻检索在现实生活中更具有实用性。

传统的基于树形结构的近似近邻检索主要思想是逐层划分数据，不断过滤大部分数据，从而减少计算量并提升检索效率。其中代表性方法包括\ KD 树\cite{bentley1975kdtree}、随机\ KD 树\cite{silpa08optkdtree}、R 树\cite{guttman1984r}、Q 树\cite{finkel1974quad}及三元投影树\cite{wang2014trinary}等。以\ KD 树为例，它实际上对应的是一个对\ $k$ 维空间的划分，构造\ KD 树时，每次使用垂直于坐标轴的超平面来将\ $k$ 维空间划分为若干个\ $k$ 维超矩形区域，其中\ KD 树的每个 节点与一个\ $k$ 维超矩形区域对应。检索查询时遵循最好节点优先原则来访问叶子节点，从而返回近邻结果。这类空间划分算法在数据维度较低的情况下能在检索精度和效率方面取得令人满意的效果，但是在高维空间中会发生维度灾难，导致基于树形结构的近似近邻检索的检索精度及效率大大下降。

为了解决高维大规模数据的近似近邻检索问题，哈希方法\cite{wang2016linear,yang2016zero,wang2018survey,ShenFM17TMM,SongJK18PR,ZhangHW16MM,Song2014Robust,luo2018scalable,yan2016srdmh} 因其检索速度快存储消耗低的优点而受到广泛关注和探索。如图\ \ref{hash_example} 所示，通过将原始高维数据映射到海明空间中的低维二进制表示，哈希方法可以显著降低多模态数据的存储代价，同时通过在海明空间中的异或操作，检索效率也会大幅度提升。哈希方法的目的是在海明空间中保持原始空间中数据点之间的相似性，即原始空间中相似的两个点在海明空间中也会尽可能相似，原始空间中不相似的两个点在海明空间中也会尽可能不相似，因此哈希学习后的二进制哈希码在一定程度上能够代替原始数据特征来进行近似近邻检索。哈希方法的具体流程为：首先通过预先设定的目标函数框架进行训练得到哈希函数以及检索数据库的哈希码（也可用学到的哈希函数生成），然后对于待查询数据使用哈希函数生成对应哈希码之后，再到检索数据库中通过异或操作找到查询数据的近邻之后即可返回检索结果。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/hash_example.eps}
\caption{哈希检索示例}
\label{hash_example}
\end{figure}

\subsection{研究意义}
\esubsection{Motivation of research}

哈希方法当前受到学术界和工业界的广泛青睐，首先在于哈希方法能够大幅度降低数据存储空间开销，具体来说，如果使用1024字节（1KB）来存储每个原始数据样本的特征向量，包含一百万个样本的数据集则占用1GB的存储空间，而如果把每个数据样本由64位（8B）的哈希码来表示, 则存储空间只需要8MB，空间消耗下降了125倍；在检索速度方面，由于使用异或操作计算哈希码间的海明距离即可得到不同哈希码之间的相似性，因此检索速度大幅提升，由此可见哈希方法的实用性；除此之外，哈希方法取得的检索精度正在不断提升，逐步达到实用的要求，体现出令人满意的有效性。

当前已存在很多优秀的哈希方法，然而大多针对单一模态的检索场景提出。传统的单模态哈希方法在同一模态数据间进行检索，如以文搜文和以图搜图等相关应用。随着信息技术的快速发展及数据的爆炸性增长，数据的表现形式也日益多样化，导致传统的单模态哈希方法无法解决模态间交叉检索的问题，如以文搜图或以图搜文等，于是多模态哈希尤其是跨模态哈希\cite{bronstein10cmssh,masci14multimodal,zhen12probabilistic,Chen2017Predicting,ZhangPF17MM,luo2018sdmch,xu2016Dictionary} 应运而生，主要思想为将多个模态数据映射到一个公共子空间中，在公共子空间中将不同模态数据量化为二值哈希码并计算不同模态数据间的相似性。

目前已有很多跨模态哈希方法提出，并取得了不错的跨模态检索效果，但是仍有几个限制其性能的问题存在：一些方法对离散条件进行松弛化，导致生成的哈希码有较大的量化误差，使得最终哈希码的检索效果下降；也有一些方法直接进行离散优化，但都以牺牲训练时间为代价，导致优化所需时间大大增加；在监督信息的选择上，有的方法选择使用$\ n\times n$ 的相似性矩阵进行相似性保持，但这会导致其训练的时间复杂度上升到$O(n^2)$，进而增加了其扩展到大规模数据集的难度。

综合考虑上述问题之后，本文提出一种新的有监督跨模态哈希方法――基于矩阵分解的可扩展离散哈希。该方法对原始特征核化后进行矩阵分解，并结合标签信息的语义嵌入来产生一个公共子空间，从而尽可能的保持模态间和模态内的语义相似性；同时，通过使用标签矩阵而非相似性矩阵，该方法的训练复杂度始终与数据集规模保持为线性关系，可方便的扩展到大规模多模态数据集上；为了解决离散优化问题，引入正交旋转矩阵来最小化训练过程中的量化误差，并使用迭代优化的方式来进一步减小量化误差。

\section{国内外研究现状}
\esection{Related works}

现有的哈希方法大致可根据其处理模态数量分为两类：单模态哈希和跨模态哈希。传统的单模态哈希方法只考虑一种模态数据，通过引入先进的机器学习理论构造目标函数来学习哈希函数和哈希码。目前多种单模态哈希方法已被提出并表现出良好的单模态数据检索性能。根据哈希方法中是否有监督信息被使用，单模态哈希方法可分为无监督单模态哈希、半监督单模态哈希和有监督单模态哈希。

实际应用中，由于多模态数据的飞速增长，多模态数据之间的检索成为亟待解决的问题，因此跨模态哈希检索应运而生，如以文搜图或以图搜文等。跨模态哈希检索的一个关键问题是如何处理来自不同概率分布的多模态数据，为了解决这个问题，现有的跨模态哈希方法大致可以分为两类：模态独立哈希和集成哈希。同时，由于近年来深度模型表现出强大的特征表示能力，单模态和跨模态哈希均开始与深度学习相结合，并取得了卓越的检索效果。

接下来通过对上述几个方面进行展开来详细介绍当前学术界对于哈希方法的研究进展。

\subsection{无监督单模态哈希方法}
\esubsection{Unsupervised single-modal hashing methods}

无监督单模态哈希方法不借助任何监督信息（如标签、tag等），只用原始数据特征来学习哈希函数并保持原始空间中数据点的局部结构和语义相似性。其中代表方法包括谱哈希（Spectral Hashing, SH）\cite{weiss09sh}、锚点图哈希（Anchor Graph Hashing, AGH）\cite{liu2011agh}、自教哈希（Self-Taught Hashing, STH）\cite{zhang2010self}、 迭代量化哈希（Iterative Quantization, ITQ）\cite{gong11itq}、图离散哈希（Discrete Graph Hashing, DGH）\cite{liu2014discrete}、可扩展图哈希（Scalable Graph Hashing, SGH）\cite{jiang2015scalable}等。

谱哈希（SH）从图分割的角度对图像进行二值编码，它对原始的\ NP-hard 离散优化问题进行松弛，通过对图拉普拉斯矩阵的特征向量进行二值化操作来生成最终的哈希码矩阵，然而谱哈希由于求解\ $n \times n$ 的图拉普拉斯特征向量的时间复杂度较高，因此在实际应用过程中仍存在问题。

为了解决谱哈希求解图拉普拉斯特征向量速度慢耗时长的问题，锚点图哈希（AGH）使用近似近邻图来代替原始的拉普拉斯图矩阵，样本间的相似性通过少数锚点来确定。由于锚点图邻接矩阵的低秩特性，从而使得图拉普拉斯特征向量的求解可在线性时间内完成，因此能够快速生成所需哈希码。

考虑到传统的哈希方法只对见过的数据样本起作用而对之前未见过的样本适应性不好的问题，自教哈希（STH）提出首先对输入数据使用当前性能较好的无监督哈希方法生成$l$位的哈希码，然后使用生成的哈希码作为监督信息，训练$l$个分类器作为哈希函数，从而提高对之前未见过的查询样本的适应性。

考虑到数据样本在每个主成分分析（Principle Component Analysis, PCA）方向上的方差不同，具体来说，高方差\ PCA 方向携带更多信息，因此传统哈希方法将每个\ PCA 方向编码成相同数目的哈希码位数会导致检索性能变差。迭代量化哈希（ITQ）先对原始特征进行\ PCA 降维得到中间表示，然后引入随机旋转矩阵来最小化中间表示和哈希码之间的量化误差，从而使得各个\ PCA 方向的方差更加平衡，哈希方法的检索效果也大大提高。

由于很多无监督哈希方法随着哈希码位数增加而检索性能下降，而最主要的原因在于这些方法的优化策略采用先松弛离散约束得到实值表示，训练结束后对该实值表示进行二值化得到最终的哈希码，这种优化方法大大增加了量化误差，因此图离散哈希（DGH）提出离散优化框架来降低量化误差，同时采用锚点图来捕捉大规模数据集中隐含的近邻结构。

然而传统的基于图的无监督哈希方法依然存在构建图的高复杂度问题，从而不能达到令人满意的效果，因此可扩展图哈希（SGH）利用了特征转换来有效地逼近整个图形而无需显式计算相似度图矩阵，并在此基础上提出了一种顺序学习方法以逐位方式学习哈希函数。

\subsection{有监督单模态哈希方法}
\esubsection{Supervised single-modal hashing methods}

有监督单模态哈希方法利用给定的监督信息来构建数据间的相似性，从而更好地进行哈希学习的相似性保持，使得原始空间中相似（不相似）的样本在海明空间中仍然相似（不相似）。比较典型的有监督单模态哈希方法有核监督哈希 （Kernel-based Supervised Hashing, KSH）\cite{liu12ksh}、 隐义监督哈希（Latent Factor Hashing, LFH）\cite{zhang2014lfh}、两步哈希（Two-Step Hashing, TSH）\cite{lin2013tsh}、快速监督哈希（Fast Supervised Hashing, FastH）\cite{lin14fasthash}、监督离散哈希（Supervised Discrete Hashing, SDH）\cite{shen15sdh}和列采样离散监督哈希 （ COlumn Sampling based DIscrete Supervised Hashing, COSDISH）\cite{kang16cosdish}。

先前的哈希检索方法不太适用于大规模的图像数据检索因为它们都是直接优化海明距离，但是因为海明距离是非凸且非平滑的，导致损失函数太过复杂以致难于优化，因此核监督哈希（KSH）推导出海明距离和哈希码的内积本质上是等价的，并借助核技术对线性不可分的数据进行优化，从而设计出了基于相似性矩阵和核技术的损失函数，并使用了贪婪算法来按位求解哈希函数。

大多数现有的哈希方法应用单一形式的哈希函数，且优化过程通常与该特定形式深度耦合，而这种紧密耦合限制了方法响应数据的灵活性，并且可能导致难以解决的复杂优化问题。两步哈希（TSH）提出了一个灵活而简单的框架，它能够适应不同类型的损失函数和哈希函数，并简化新的特定问题哈希方法的开发，首先通过对损失函数的优化来得到哈希码，然后以哈希码为监督信息训练分类器的形式得到哈希函数。

针对之前提出的非线性哈希函数，通常采用的实现非线性的手段多为使用核哈希函数，如\ KSH 和\ TSH，实验表明核哈希函数的引入大大提升了线性哈希函数的检索性能，然而当特征维度增高时，核函数的训练和测试成本也随之增加，从而导致实际应用中的资源不足。针对这个问题，快速监督哈希使用决策树作为哈希方法的非线性哈希函数，从而避免了核函数带来的巨大消耗，且决策树因其训练和测试速度快而为工业界所喜爱，因此更具有使用价值。快速监督哈希（FastH）采用两步哈希的策略，第一步先将哈希码的优化问题转换为一个二进制二次规划问题来逐位求解哈希码，并采用了分块搜索的图分割策略来得到哈希码，第二步使用第一步得到的哈希码作为监督信息，结合\ Adaboost 集成策略来训练决策树作为哈希函数。

隐义监督哈希（LFH）基于潜在因子模型将成对样本之间相似性的似然函数优雅地建模为相应数据点之间的海明距离的函数，同时为了对大规模问题进行建模，提出了一种随机学习优化的线性时间变种用于快速学习参数，以达到检索性能和效率的大幅提升。

监督离散哈希（SDH）没有采用对离散约束进行松弛的做法，也就是哈希码在训练过程中一直是离散的二值向量，因为传统的基于松弛技术的哈希方法会导致较大的量化误差。但是保持离散约束会增大优化难度，因此\ SDH 采用离散循环坐标下降（Discrete Cyclic Coordinate descent, DCC）方法来逐位哈希码迭代求解，通过牺牲部分训练代价来得到更好的哈希码。

为了解决之前哈希方法耗时和对大规模数据集扩展性差的问题，列采样离散监督哈希（COSDISH）采用迭代优化的方式，在每次迭代中，从语义相似度矩阵中对几列进行采样，然后将哈希码分解为两部分，这两部分可以以离散方式交替优化。

\subsection{深度单模态哈希方法}
\esubsection{Deep single-modal hashing methods}

由于最近深度模型展现出极其强大的特征表示能力，一些基于深度模型的单模态哈希方法也被提出，如卷积神经网络哈希（Convolutional Neural Network Hashing, CNNH）\cite{xia14cnnh}，基于特征学习的深度监督哈希（Deep Pairwise-Supervised Hashing, DPSH）\cite{li2015dpsh}。卷积神经网络哈希（CNNH）把卷积神经网络直接与哈希算法进行了结合，借鉴了两步哈希的思想，首先通过使用相似度矩阵作为监督信息得到哈希码矩阵，然后将卷积神经网络（CNN）作为哈希函数结合交叉熵损失，并以哈希码作为监督信息，从而将哈希函数学习问题转换为多标签分类问题，最后加入分类的\ softmax 损失函数来进一步提升性能。实验表明\ CNNH 相比传统的浅层哈希方法取得了显著的性能提升，然而它将哈希码和哈希函数的学习过程分为两个互相独立的过程，仍然不是端到端的方法，因此深度学习强大的特征表示能力并没有被充分挖掘。基于特征学习的深度监督哈希（DPSH）则设计了一个端到端的框架，同时进行哈希函数（卷积神经网络）以及哈希码的学习，从而使得图像检索精度得到进一步提升。

\subsection{模态独立跨模态哈希方法}
\esubsection{Modality-specific cross-modal hashing methods}

模态独立跨模态哈希方法对每个模态学习一个独立海明空间中的哈希码，如跨模态相似性敏感哈希（Cross-Modal Similarity Sensitive Hashing, CMSSH）\cite{bronstein10cmssh}、跨视角哈希（Cross-View Hashing, CVH）\cite{kumar11cvh}、共正则化哈希（Co-Regularized Hashing, CRH）\cite{zhen2012crh}、跨媒体哈希（Inter-Media Hashing, IMH）\cite{song13imh}等。

跨模态相似性敏感哈希（CMSSH）将相似性敏感的哈希方法扩展到大规模多模态数据上，尝试将不同的模态嵌入到公共度量空间中，即把每种模态特征投影到哈希码建模为二值分类问题，并使用标准\ AdaBoost 进行学习。

跨视角哈希（CVH）是谱哈希（SH）的多模态扩展，首先将学习哈希函数的问题表达为大规模多模态数据上的松弛约束最小化问题，然后通过求解广义特征值问题来解决最小化问题。

共正则化哈希（CRH）通过求解\ DC（Difference of Convex functions, 凸函数之间的差异）程序来学习每个位的哈希函数，同时通过\ boosting 流程进行多位的学习，以便可以顺序地最小化由哈希函数引入的偏差。

跨媒体哈希（IMH）探讨了来自不同数据源的多种模态类型之间的相关性，引入了模态间一致性和模态内部一致性，以发现一个共同的汉明空间，并使用线性回归和正则化模型来学习针对特定模态的哈希函数。

\subsection{集成跨模态哈希方法}
\esubsection{Integrated cross-modal hashing methods}

然而模态独立哈希需要为每一个模态都保存其数据库相应的哈希码，这就增加了检索和存储的代价。相对而言，集成哈希方法为所有模态寻找一个公共海明空间，所有模态的数据均映射到公共海明空间中生成对应哈希码，最终只需要一个公共的数据库哈希码，从而避免了模态独立哈希巨大的检索和存储代价，因此应用更为广泛，如隐语义稀疏哈希（Latent Semantic Sparse Hashing, LSSH）\cite{zhouJ14LSSH}、协同矩阵分解哈希（Collective Matrix Factorization Hashing, CMFH）\cite{ding14cmfh}、语义相关性最大化哈希（Semantic Correlation Maximization, SCM）\cite{zhang14scm}、语义保持哈希（Semantics Preserving Hashing, SePH）\cite{lin15seph}、有监督矩阵分解哈希（Supervised Matrix Factorization Hashing, SMFH）\cite{Liu16smfh}、离散跨模态哈希（Discrete Cross-modal Hashing, DCH）\cite{xu17dch}等。

当前大多数跨模态哈希方法通过线性投影将异构数据嵌入到联合抽象空间中，然而这些方法未能更有效地弥合语义鸿沟并捕获高级潜在语义信息，因此隐语义稀疏哈希（LSSH）使用稀疏编码捕获图像的显著结构以及使用矩阵分解来从文本中学习潜在的语义概念，然后将两个模态学习到的潜在语义信息映射到公共的语义空间中，从而更好地弥合语义鸿沟。

协同矩阵分解哈希（CMFH）假设一个数据样本的每个模态生成相同的哈希码，而不是来自不同模态的某些哈希码的组合或串联，通过对不同模态数据使用带潜在因子的协同矩阵分解模型来学习统一的哈希码。

语义相关性最大化哈希（SCM）通过最大化语义相关性将语义标签集成到学习过程中，通过避免显式计算成对相似性矩阵从而可以利用所有监督信息进行线性时间复杂度的训练，这使其可扩展到大规模数据集，并提出一种顺序学习方法来逐位学习哈希函数，每个位的哈希均具有闭式解，因此训练过程中不需要超参数和停止条件。

语义保持哈希（SePH）是一种“两步走”的非线性跨模态哈希方法，是两步哈希（TSH）的多模态哈希扩展。给定训练数据间的语义相似性作为监督信息后，SePH 将该相似性矩阵转换为概率分布的形式，从而以概率分布来代替训练数据的语义相似性，然后使用核化的逻辑回归（Logistic Regression）来实现非线性的哈希函数，并通过\ Kullback-Leibler 散度最小化来将其与海明空间中的待学习哈希码近似。
%语义保持哈希（SePH）将语义相似性矩阵视为监督信息，然后将它们转换为概率分布，，并通过最小化Kullback-Leibler 散度。

有监督矩阵分解哈希（SMFH）通过不同模态的非负协同矩阵分解来解决多模态哈希问题，通过图正则化来保持多模态原始特征之间的相似性，同时在语义标签可用时被合并到学习过程中，从而提高检索的准确性。

离散跨模态哈希（DCH）是监督离散哈希（SDH）在多模态场景下的扩展，同样在训练过程中保持哈希码的离散特性并采用离散循环坐标下降（DCC）方法来逐位哈希码迭代求解，尽管牺牲了部分训练代价，但最终的哈希检索性能得到了大幅度提升。

\subsection{深度跨模态哈希方法}
\esubsection{Deep cross-modal hashing methods}

除此之外，许多基于深度模型的跨模态哈希方法也已被提出，并且取得了突破性进展，如深度跨模态哈希（Deep Cross-Modal Hashing, DCMH）\cite{jiang2017dcmh}、深度视觉语义哈希（Deep Visual-Semantic Hashing, DVSH）\cite{cao2016dvsh}、对抗跨模态检索（Adversarial Cross-Modal Retrieval, ACMR）\cite{wang2017acmr}等。

深度跨模态哈希（DCMH）\cite{jiang2017dcmh}是一个端到端的跨模态哈希学习框架，将特征学习和哈希码学习集成到同一个深度学习框架中，为每个模态提供一个深度神经网络，并且在学习过程中始终保持哈希码的离散特性。

由于目前大多数跨模态哈希方法均不能捕捉图像的空间依赖性和文本句子的时间动态以学习强大的特征表示和减少不同模态的异质性的跨模态嵌入，因此深度视觉语义哈希（DVSH）\cite{cao2016dvsh}基于图像的卷积神经网络（Convolutional Neural Network, CNN）、文本的循环神经网络（Recurrent Neural Network, RNN）以及整合所有事物的结构化最大边缘目标函数，以实现相似性保持和高质量哈希码的学习。

然而，现有的基于深度神经网络的跨模态检索方法仅仅关注于保持两个耦合的跨模态项（如一张图片和一段文本）之间的成对相似性，而现实中对于一个模态的一个样本来说，可能同一个模态中存在多个语义不同的样本，因此仅通过保持成对相似性的方式学出的公共表示空间是无法充分保持数据的隐含跨模态语义结构的。对抗跨模态检索（ACMR）\cite{wang2017acmr}利用了对抗生成网络（Generative Adversarial Networks, GAN）的思想，通过特征映射器和模态分类器两个组成部分的最大最小化博弈来获得最优的公共语义子空间，可以确保学习到的公共语义表示同时保持同一模态中的可区分性以及模态之间同一样本的不变性，从而使得模态间和模态内的语义结构能够得到更好的保持。

\section{本文主要工作}
\esection{Main contents}

目前已经存在许多优秀的跨模态哈希方法，然而仍然存在一些亟待优化的问题：1）大多数方法松弛了哈希码的离散约束以便于优化，然后将学习的实值解量化为二进制哈希码，这可能产生很大的量化误差并使获得的哈希码不可靠；2）一些方法，例如离散跨模态哈希（DCH）\cite{xu17dch}，试图借助离散循环坐标下降（DCC）方法来保持离散约束并逐位求解优化问题，然而逐位优化使得训练非常耗时；3）还有一些方法依赖于\ $n\times n$ 的相似性矩阵来度量样本之间的相似性，例如\ SePH 和\ FSH，但对于大规模数据集来说，这将增加计算复杂性和内存成本，导致这些方法不可扩展，而接近扩展性问题通用的方法是随机选取数据集的子集进行训练而不是利用所有样本，这又导致跨模态方法的检索性能有所下降。

为了解决上述挑战，本文提出了一种新颖的监督跨模态哈希方法，即基于矩阵分解的可扩展离散哈希（SCRATCH）。基于不同模态共享相同的潜在语义空间，且这个潜在的语义空间与真实的标签语义空间是一致的假设，SCRATCH 首先在非线性核化后的特征上利用协同矩阵分解（CMF）结合标签的语义嵌入来找到潜在的语义空间，从而保持模态间和模态内的相似性，然后通过正交旋转矩阵来最小化训练过程中量化误差的同时，学习到所需要的哈希码和哈希函数。由于训练过程中只用到了语义标签而非成对的相似性矩阵，SCRATCH 可在线性时间内训练完毕，且在训练过程中保持了哈希码的离散约束，使得学习到的哈希码质量更高。


\section{本文组织结构}
\esection{Thesis framework}

本论文的组织结构如下：

第一章介绍了本文课题的研究背景及意义，分析了国内外研究现状及其存在的问题，从而引出本文的主要工作及创新点；

第二章详细描述了本文提出的跨模态哈希检索方法，包括损失函数设计、优化过程、算法扩展以及复杂度和定理分析；

第三章进行了全面且详尽的实验，包括算法的实现细节、对比方法以及实验结果的分析；

最后一章对全文的主要创新点及不足之处进行了总结，并针对论文的不足进行了对未来工作的展望。

